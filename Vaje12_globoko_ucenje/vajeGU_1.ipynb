{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globoko učenje, vaje 1\n",
    "## 1. Nevronske mreže s knjižnico pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Instalacija\n",
    "PyTorch je trenutno verjetno najpopularnejša knjižnica za delo z nevronskimi mrežami. Za instalacijo najprej aktivirajmo pythonovo okolje, ki ga uporabljamo za vaje (navigiramo v mapo okolja, podmapa Scripts, ter v ukazni vrstici kličemo **activate**). Instalirajmo osnoven paket pytorcha ter različico za grafovske nevronske mreže: **pip install torch torch-geometric**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Nalaganje podatkov\n",
    "Vajam so priložene datoteke s podatki o znanstvenih člankih. Vsak od njih je opisan s frekvencami posameznih besed (bag-of-words pristop), ki so podane v datoteki **podatki1_x.txt**. Vsak članek je kategoriziran v eno izmed sedmih znanstvenih področij. Razredi so podani v **podatki1_y.txt**. Poleg tega so podatki že razdeljeni v učno in testno množico. Datoteka \"podatki1_train_mask.txt\" podaja binarne vrednosti, ki povedo, ali je primer v učni množici.\n",
    "\n",
    "Naloži vse tri, najlažje z uporabo **np.loadtxt**, ter si jih oglej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.loadtxt('podatki1_x.txt')\n",
    "y = np.loadtxt('podatki1_y.txt')\n",
    "train = np.loadtxt('podatki1_train_mask.txt')\n",
    "\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch za predstavitev podatkov uporablja svoj razred Tensor (**torch.tensor**), v katerega moramo pretvoriti svoje podatke. Prav tako moramo zagotoviti, da so podatki pravega tipa - značilke so realna števila (**float**), razredi so celoštevilski (**long**), učna in testna maska pa sta binarni (**bool**). Poskrbi za ustrezno pretvorbo podatkov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_data = torch.tensor(X).float()\n",
    "y_data = torch.tensor(y).long()\n",
    "train_mask = torch.tensor(train).bool()\n",
    "test_mask = torch.tensor(np.logical_not(train)).bool() #pomagaš si lahko z np.logical_not\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sestavljanje nevronske mreže\n",
    "\n",
    "Mrežo implementiramo kot razred, ki deduje po **torch.nn.Module**. Definirati mora metodi **__init__**, v kateri inicializiramo vse gradnike, ter **forward** ki opisuje potek izračuna v naši mreži. Ključni elementi:\n",
    "- Linear: polno povezana plast, osnovni gradnik navadnih nevronskih mrež. Podati ji moramo dimenzije vhoda in izhoda, pri čemer se mora izhod n-te plasti ujemati z vhodom n+1-te plasti. Vhod prve plasti je število značilk, izhod zadnje plasti pa število razredov.\n",
    "- relu: Rectified Linear Unit - aktivacijska funkcija, ki mreži daje nelinearnost. Aktivacijske funkcije postavljamo za posamezne plasti, pomembno pa je, da je ne postavimo pred izhod, saj bi nam pokvarila napovedi.\n",
    "- dropout: element, ki pri treniranju zavrže del nevronov v posamezni plasti (delež p), s čimer se borimo proti preprileganju.\n",
    "\n",
    "Dopolni definicijo nevronske mreže!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape[1])\n",
    "size_input = x_data.shape[1]\n",
    "size_output = len(y_data.unique())\n",
    "print(size_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n_skritih):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.lin1 = Linear(size_input, n_skritih)\n",
    "        self.lin2 = Linear(n_skritih, n_skritih)\n",
    "        self.lin3 = Linear(n_skritih, size_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Treniranje nevronske mreže\n",
    "\n",
    "V knjižnici pytorch moramo učno zanko napisati sami. Za začetek potrebujemo naslednje elemente:\n",
    "- model (instanca mreže, ki smo jo definirali zgoraj, priporočeno število nevronov v skriti plasti: 16)\n",
    "- kriterijska funkcija, ki na podlagi napovedi mreže in pravih vrednosti izračuna napako. Uporabili bomo prečno entropijo (**torch.nn.CrossEntropyLoss**).\n",
    "- optimizator. Uporabili bomo Adam (**torch.optim.Adam**). Podati mu moramo parametre mreže, ki jih dobimo z **model.parameters()**, dobro pa je definirati tudi hitrost učenja (npr. **lr=0.01**) in parameter L2 regularizacije (npr. **weight_decay=0.0005**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(n_skritih=16)\n",
    "kriterijska_funkcija = torch.nn.CrossEntropyLoss()\n",
    "optimizator = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koraki učne zanke so sledeči:\n",
    "1. s klicem funkcije **optimizator.zero_grad()** postavimo odvode na nič\n",
    "2. učne podatke pošljemo skozi mrežo (**model(podatki)**) ter si shranimo rezultat\n",
    "3. na podlagi rezultata in pravih vrednosti izračunamo napako s kriterijsko funkcijo\n",
    "4. izračunamo odvode s klicem **napaka.backward()** \n",
    "5. posodobimo parametre mreže na podlagi odvodov s klicem **optimizator.step()**\n",
    "\n",
    "Pomembno je še, da pred začetkom treniranja modelu povemo, da je čas za treniranje s klicem model.train(). Razlog je, da se dropout uporablja samo med treniranjem, ne pa med evaluacijo in uporabo mreže.\n",
    "\n",
    "Dopolni!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 1.6781\n",
      "Epoch: 020, Loss: 1.2324\n",
      "Epoch: 030, Loss: 0.9818\n",
      "Epoch: 040, Loss: 0.7924\n",
      "Epoch: 050, Loss: 0.7121\n",
      "Epoch: 060, Loss: 0.6555\n",
      "Epoch: 070, Loss: 0.5943\n",
      "Epoch: 080, Loss: 0.5877\n",
      "Epoch: 090, Loss: 0.5527\n",
      "Epoch: 100, Loss: 0.4642\n",
      "Epoch: 110, Loss: 0.5736\n",
      "Epoch: 120, Loss: 0.5858\n",
      "Epoch: 130, Loss: 0.4499\n",
      "Epoch: 140, Loss: 0.5542\n",
      "Epoch: 150, Loss: 0.4564\n",
      "Epoch: 160, Loss: 0.4252\n",
      "Epoch: 170, Loss: 0.5871\n",
      "Epoch: 180, Loss: 0.4108\n",
      "Epoch: 190, Loss: 0.5036\n",
      "Epoch: 200, Loss: 0.5407\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "      optimizator.zero_grad()\n",
    "      x = model(x_data[train_mask])\n",
    "      napaka = kriterijska_funkcija(x, y_data[train_mask])\n",
    "      napaka.backward()\n",
    "      optimizator.step()\n",
    "      return napaka\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch%10 == 0:\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Evaluacija nevronske mreže\n",
    "\n",
    "Ko smo mrežo natrenirali, želimo izračunati še njeno napako na testni množici. Pri tem:\n",
    "- prej mreži povemo, da je čas za evaluacijo s klicem **model.eval()**,\n",
    "- pošljemo testne podatke skozi mrežo in si shranimo rezultat\n",
    "\n",
    "Oglej si izhod iz mreže in premisli, kaj pomeni. Potem izračunaj testno natačnost. V pomoč ti bo funkcija **argmax(dim=1)** rezultata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testna natancnost: 0.4942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "out = model(x_data[test_mask])\n",
    "y_pred = out.argmax(dim=1)\n",
    "y_true = y_data[test_mask]\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f'Testna natancnost: {acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako dobra je natančnost mreže? Za primerjavo izračunaj še testno napako modela, ki vedno napove najpogostejši razred, ali pa naključnega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12889408099688474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(x_data[train_mask], y_data[train_mask])\n",
    "dummy_pred = dummy_clf.predict(x_data[test_mask])\n",
    "dummy_acc = accuracy_score(y_data[test_mask], dummy_pred)\n",
    "print(dummy_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grafovske nevronske mreže s knjižnico torch-geometric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za grafovske nevronske mreže bomo uprabili paket **torch-geometric**, krajše imenovan pyG. Delali bomo z istimi podatki o znanstvenih člankih, vendar bomo tokrat uporabili še informacijo o citatih, ki je podana v obliki grafa. Vsak članek je vozlišče na grafu, vozlišča pa sta povezana, če je eden izmed člankov citiral drugega. Ideja je, so članki, ki se citirajo, verjetno iz istega področja. \n",
    "\n",
    "### 2.1 Nalaganje podatkov\n",
    "\n",
    "Uporabili bomo iste podatke kot prej, le da tokrat potrebujemo še **podatki1_povezave.txt**, ki ga lahko prav tako naložiš z **np.loadtxt**. Oglej si, v kakšni obliki so povezave podane, potem pa jih spremeni v torch.tensor celoštevilskega tipa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])\n"
     ]
    }
   ],
   "source": [
    "povezave = np.loadtxt('podatki1_povezave.txt')\n",
    "povezave = torch.tensor(povezave).long()\n",
    "print(povezave)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj sicer imamo vse kar potrebujemo, ampak za ilustracijo poglejmo še pyG-jev objekt Data, ki nam lahko pove kup uporabnih informacij o grafu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Število vozlišč: 2708\n",
      "Število povezav: 10556\n",
      "Povprečno število povezav na vozlišče: 3.90\n",
      "Izolirana vozlišča: False\n",
      "Self-loops: False\n",
      "Neusmerjen: True\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data = Data(x=x_data, y=y_data, edge_index=povezave)\n",
    "\n",
    "print(f'Število vozlišč: {data.num_nodes}')\n",
    "print(f'Število povezav: {data.num_edges}')\n",
    "print(f'Povprečno število povezav na vozlišče: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Izolirana vozlišča: {data.has_isolated_nodes()}')\n",
    "print(f'Self-loops: {data.has_self_loops()}')\n",
    "print(f'Neusmerjen: {data.is_undirected()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sestavljanje grafovske nevronske mreže\n",
    "\n",
    "Definicija mreže bo zelo podobna tisti v 1.3. Namesto polno povezanih linearnih plasti bomo uporabili grafovske konvolucijske plasti **GCNConv**, ki jih inicializiramo enako kot prej. Razlika pa je, da jim pri izračunu poleg značilk podamo tudi povezave grafa.\n",
    "\n",
    "Dopolni!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, n_skritih):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.conv1 = GCNConv(size_input, n_skritih)\n",
    "        self.conv2 = GCNConv(n_skritih, n_skritih)\n",
    "        self.conv3 = GCNConv(n_skritih, size_output)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Treniranje grafovske nevronske mreže\n",
    "\n",
    "Koda za naše grafovske nevronske mreže je skoraj enaka kot pri navadni nevronski mreži, le da mreži podamo še graf. Pomembna razlika pa je, da moramo tokrat modelu podati vse podatke za izračun, ne samo učne množice, sicer ne more uporabiti celotnega grafa in vrže napako. Seveda pa pri izračunu napake upoštevamo samo učno množico.\n",
    "\n",
    "Natreniraj svojo grafovsko nevronsko mrežo!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Treniranje grafovske nevronske mreže"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 1.1551\n",
      "Epoch: 020, Loss: 0.4449\n",
      "Epoch: 030, Loss: 0.1861\n",
      "Epoch: 040, Loss: 0.0620\n",
      "Epoch: 050, Loss: 0.0742\n",
      "Epoch: 060, Loss: 0.0569\n",
      "Epoch: 070, Loss: 0.0756\n",
      "Epoch: 080, Loss: 0.1085\n",
      "Epoch: 090, Loss: 0.0591\n",
      "Epoch: 100, Loss: 0.0334\n",
      "Epoch: 110, Loss: 0.0567\n",
      "Epoch: 120, Loss: 0.0565\n",
      "Epoch: 130, Loss: 0.0536\n",
      "Epoch: 140, Loss: 0.0680\n",
      "Epoch: 150, Loss: 0.0435\n",
      "Epoch: 160, Loss: 0.0356\n",
      "Epoch: 170, Loss: 0.0305\n",
      "Epoch: 180, Loss: 0.0276\n",
      "Epoch: 190, Loss: 0.0680\n",
      "Epoch: 200, Loss: 0.0261\n"
     ]
    }
   ],
   "source": [
    "model = GCN(n_skritih=16)\n",
    "kriterijska_funkcija = torch.nn.CrossEntropyLoss()\n",
    "optimizator = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
    "\n",
    "def train():\n",
    "      optimizator.zero_grad()  \n",
    "      rezultat = model(x_data, povezave) \n",
    "      napaka = kriterijska_funkcija(rezultat[train_mask], y_data[train_mask]) \n",
    "      napaka.backward()  \n",
    "      optimizator.step()  \n",
    "      return napaka\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch%10 == 0:\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluacija grafovske nevronske mreže\n",
    "\n",
    "Izračunaj testno napako nove mreže podobno kot prej. Je informacija o citatih izboljšala rezultat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "gout = model(x_data, povezave)\n",
    "y_pred_g = gout.argmax(dim=1)\n",
    "y_true = y_data[test_mask]\n",
    "testna_natancnost = accuracy_score(y_true, y_pred_g[test_mask])\n",
    "\n",
    "print(f'Test Accuracy: {testna_natancnost:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Arhitekture mrež in hiperparametri\n",
    "\n",
    "Arhitekura mreže ter razni hiperparametri imajo velik vpliv na delovanje. Pogosto jih moramo optimizirati v zahtevnih računskih eksperimentih, podobno kot smo to počeli v DN1. Da dobiš občutek, kaj se dogaja, se vrni k obema mrežama ter poskusi:\n",
    "- dodati tretjo linearno plast v navadno nevronsko mrežo,\n",
    "- dodati tretjo konvolucijsko plast v grafovsko nevronsko mrežo,\n",
    "- dodati linearno plast na konec grafovske nevronske mreže.\n",
    "\n",
    "Potem preizkusi še vpliv parametrov:\n",
    "- število nevronov v linearni ali konvolucijski plasti\n",
    "- verjetnost v dropout plasti\n",
    "- izbira aktivacijske funkcije (https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "- parameter hitrosti učenja v optimizatorju\n",
    "- parameter L2 regularizacije v optimizatorju\n",
    "- število epohov"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatno\n",
    "\n",
    "Današnje vaje so bile prirejene iz drugega učnega zvezka pyG-jeve dokumentacije: https://pytorch-geometric.readthedocs.io/en/latest/get_started/colabs.html\n",
    "\n",
    "Napovedovali smo kategorije posameznih vozlišč v grafu. Drugačen tip problema, ki se pogosto rešuje z grafovskimi nevronskimi mrežami, je napovedovanje kategorije celotnega grafa, pri čemer so naši podatki sestavljeni iz množice grafov. Primer je napovedovanje lastosti molekul, ki jih lahko opišemo kot povezave med atomi (vozlišči). Reševanje takega problema naslavlja tretji zvezek v zgornji dokumentaciji.\n",
    "\n",
    "Če te tematika zanima, lahko nadaljuješ s pyG-jevimi učnimi zvezki."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
