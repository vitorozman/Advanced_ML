{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "okuzeni_all = pd.read_csv('okuzeni.csv')\n",
    "NAMES = [ \"ljubljana\", \"maribor\", \"kranj\", \"koper\", \"celje\", \"novo_mesto\", \"velenje\", \"nova_gorica\", \"kr≈°ko\", \"ptuj\", \"murska_sobota\", \"slovenj_gradec\"]\n",
    "NAMES = 'ljubljana'\n",
    "\n",
    "okuzeni = torch.tensor(okuzeni_all[NAMES].values).float()\n",
    "okuzeni_diff = okuzeni.diff(axis=0)\n",
    "okuzeni_log = torch.log(okuzeni)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "okuzeni_norm = scaler.fit_transform(okuzeni.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = okuzeni_norm\n",
    "\n",
    "def create_sequences(data, seq_length, pred_length):\n",
    "    \"\"\" Sprejme \n",
    "            data ... torch tensor \n",
    "            seq_length ... dolzina sekvenc\n",
    "        Vrne \n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for i in range(len(data)-seq_length-pred_length):\n",
    "        sequences.append((data[i:i+seq_length], data[i+seq_length:i+seq_length+pred_length]))\n",
    "    return sequences\n",
    "\n",
    "def create_sequences_normal(data, seq_length, pred_length):\n",
    "    \"\"\" Sprejme \n",
    "            data ... torch tensor \n",
    "            seq_length ... dolzina sekvenc\n",
    "        Vrne \n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    m_s = []\n",
    "    for i in range(len(data)-seq_length-pred_length):\n",
    "        seq_learn = data[i:i+seq_length]\n",
    "        m = torch.mean(seq_learn)\n",
    "        s = torch.std(seq_learn)\n",
    "        seq_learn = (seq_learn-m)/s\n",
    "        seq_pred = data[i+seq_length:i+seq_length+pred_length]\n",
    "        seq_pred = (seq_pred-m)/s\n",
    "\n",
    "        sequences.append((seq_learn, seq_pred))\n",
    "        m_s.append((s,m))\n",
    "    return sequences, m_s\n",
    "\n",
    "\n",
    "train_data_diff = okuzeni_diff\n",
    "train_data_log = okuzeni_log\n",
    "\n",
    "seq_length = 20\n",
    "pred_length = 7\n",
    "\n",
    "train_sequences = create_sequences(train_data, seq_length, pred_length)\n",
    "#train_sequences, ms = create_sequences_normal(train_data, seq_length, pred_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(myLSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "        self.forget_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.exit_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "\n",
    "        self.hidden = torch.zeros(hidden_size)\n",
    "        self.cell = torch.zeros(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        combined = torch.cat((x, self.hidden))\n",
    "\n",
    "        ft = self.sig(self.forget_gate(combined))\n",
    "        it = self.sig(self.input_gate(combined))\n",
    "        ct_hat = self.tanh(self.i2h(combined))\n",
    "        ct = ft*self.cell + it*ct_hat\n",
    "        ot = self.sig(self.exit_gate(combined))\n",
    "        ht = ot * self.tanh(ct)\n",
    "\n",
    "        self.cell = ct.detach()\n",
    "        self.hidden = ht.detach()\n",
    "\n",
    "        return ht\n",
    "    \n",
    "    def reset_hidden(self):\n",
    "        self.hidden = torch.zeros(self.hidden_size)\n",
    "        self.cell = torch.zeros(self.hidden_size)\n",
    "\n",
    "class myLSTMnet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(myLSTMnet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru_cell = myLSTMCell(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def reset_hidden(self):\n",
    "        self.gru_cell.reset_hidden()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        for t in range(x.shape[0]):\n",
    "            h = self.gru_cell(x[t])\n",
    "            output += [self.output_layer(h)]\n",
    "\n",
    "        output = torch.stack(output)\n",
    "        return output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myLSTMnet(1, 32, 1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch \", epoch)\n",
    "    for i, (seq, labels) in enumerate(train_sequences):\n",
    "        optimizer.zero_grad()\n",
    "        model.reset_hidden()\n",
    "        y_pred = model(seq)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%100 == 0:\n",
    "            print(f'i: {i:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = train_data[-seq_length:].tolist()\n",
    "\n",
    "model = model.eval()\n",
    "test_size = train_data.shape[0]-seq_length\n",
    "\n",
    "pred = []\n",
    "true = []\n",
    "for i in range(len(train_sequences)):\n",
    "    with torch.no_grad():\n",
    "        model.reset_hidden()\n",
    "        seq = train_sequences[i][0]\n",
    "        res = model(seq)\n",
    "        #print(res)\n",
    "        #print(train_sequences[i][1])\n",
    "        pred.append(res[0].item())\n",
    "        true.append(train_sequences[i][1][0])\n",
    "#        \n",
    "#for i in range(test_size):\n",
    "#    seq = torch.FloatTensor(test_inputs[-seq_length:])\n",
    "#    with torch.no_grad():\n",
    "#        model.reset_hidden()\n",
    "#        res = model(seq)\n",
    "#        test_inputs.append(res[0].item())\n",
    "from sklearn.metrics import r2_score\n",
    "#test_data = train_data[seq_length:-pred_length]\n",
    "\n",
    "#print(test_data.shape)\n",
    "#print(len(test_inputs[seq_length:-pred_length]))\n",
    "#print(r2_score(test_data.numpy(), test_inputs[seq_length:-pred_length]))\n",
    "print(r2_score(true, pred))\n",
    "\n",
    "\n",
    "plt.plot(pred)\n",
    "plt.show()\n",
    "plt.plot(true)\n",
    "#plt.plot(okuzeni_log)\n",
    "plt.show()\n",
    "#actual_predictions = test_inputs[seq_length:]\n",
    "#plt.plot(okuzeni_diff.data.numpy()[-test_size:])\n",
    "#plt.plot(actual_predictions)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x.view(len(x), 1, -1))\n",
    "        x = self.fc(x.view(len(x), -1))\n",
    "        return x[-1]\n",
    "\n",
    "\n",
    "\n",
    "model = RNN(1, 32, 7)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (seq, labels) in enumerate(train_sequences):\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden = (torch.zeros(1,1,model.hidden_size))\n",
    "        y_pred = model(seq)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #if i%100 == 0:\n",
    "        #    print(f'i: {i:03d}, Loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_inputs = train_data[-seq_length:].tolist()\n",
    "\n",
    "model = model.eval()\n",
    "test_size = train_data.shape[0]-seq_length-pred_length\n",
    "print(test_size)\n",
    "for i in range(test_size-1):\n",
    "    seq = torch.FloatTensor(test_inputs[-seq_length:])\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1,1,model.hidden_size))\n",
    "        res = model(seq)\n",
    "        print(res)\n",
    "        print(train_sequences[i][1])\n",
    "        test_inputs.append(res[0].item())\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "test_data = train_data[seq_length:-pred_length]\n",
    "\n",
    "print(test_data.shape)\n",
    "print(len(test_inputs[seq_length:-pred_length]))\n",
    "print(r2_score(test_data.numpy(), test_inputs[seq_length:-pred_length]))\n",
    "\n",
    "\n",
    "plt.plot(test_inputs[seq_length:-pred_length])\n",
    "plt.plot(train_data_diff)\n",
    "#plt.plot(okuzeni_log)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
