{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSU, vaje 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Meta klasifikacija in meta regresija.\n",
    "A.1: Uporabi meta podatke iz prejsnjih dveh nalog. Razbij jih na testno in ucno mnozico. \n",
    "pyMFE nekaterih meta značilk ni mogel izračunati, zato podatki vsebujejo nekaj manjkajočih vrednosti. Odstrani stolpce z njimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name       knn      tree     bayes   best\n",
      "0           iris  0.973684  0.947368  0.973684    knn\n",
      "1            zoo  0.807692  0.923077  0.923077   tree\n",
      "2           wine  0.644444  0.888889  0.977778  bayes\n",
      "3     hayes-roth  0.550000  0.900000  0.725000   tree\n",
      "4  fri_c3_100_50  0.520000  0.880000  0.560000   tree\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x_meta_all = pd.read_csv(\"meta_features.csv\")\n",
    "x_meta = x_meta_all.dropna(axis=1).drop(\"name\", axis=1)\n",
    "y_meta_all = pd.read_csv(\"meta_target.csv\")\n",
    "print(y_meta_all.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.2: Natreniraj meta model z metodo naključnega gozda, ki bo napovedal, katera izmed metod drevo, 1NN in Bayes dela najbolje na sestavljenih meta podatkih. \n",
    "Za testiranje uporabi 5-kratno prečno preverjanje. Natančnost meta modela primerjaj z natančnostjo modela, ki vedno napove povprečno vrednost ciljne spremenjivke na učni množici (pomagaš si lahko z **sklearn.dummy.DummyClassifier**).\n",
    "\n",
    "Kakšna se ti zdi uspešnost meta modela?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5781818181818182\n",
      "0.4618181818181818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "Y = y_meta_all['best']\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "cvrf = cross_validate(rf, x_meta, Y, cv=5,\n",
    "    scoring=(['accuracy']),\n",
    "    return_train_score=True)\n",
    "\n",
    "print(np.mean(cvrf['test_accuracy']))\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "cvdummy = cross_validate(dummy, x_meta, Y, cv=5,\n",
    "    scoring=(['accuracy']),\n",
    "    return_train_score=True)\n",
    "\n",
    "print(np.mean(cvdummy['test_accuracy']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.3: Naše meta podatke sestavlja kar nekaj različnih meta značilk. Katere so pa zares pomembne in koristne? \n",
    "Nekatere metode strojnega učenja nam omogočajo oceno pomembnosti značilk, ki nam lahko pomaga odgovoriti na to vprašanje. Primeri takšnih metod so logistična regresija (izračunamo iz koeficientov **model.coef_**), odločitveno drevo (**model.feature_importances_**) in naključni gozd (**model.feature_importances_**).\n",
    "\n",
    "Katerih 5 meta značilk je najpomembnejših? Izriši še stolpični diagram (**plt.bar**) pomembnosti meta značilk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['leaves_homo.sd', 'tree_depth.mean', 'nr_inst', 'tree_depth.sd',\n",
      "       'leaves_branch.sd'],\n",
      "      dtype='object')\n",
      "Index(['attr_conc.mean', 'class_conc.mean', 'attr_conc.sd', 'attr_ent.sd',\n",
      "       'tree_shape.sd'],\n",
      "      dtype='object')\n",
      "Index(['var_importance.sd', 'leaves_branch.sd', 'nodes_per_level.mean',\n",
      "       'leaves_homo.sd', 'tree_shape.sd'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitorozman/Documents/School/Master/1.Letnik/ML/Advanced_ML/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(x_meta, Y, test_size=0.2, random_state=42)\n",
    "lr = LogisticRegression().fit(x_meta, Y)\n",
    "implr = lr.coef_\n",
    "#print(np.argsort(implr)[0][-6:-1])\n",
    "print(x_meta.columns[np.argsort(implr)[0][-6:-1]])\n",
    "\n",
    "\n",
    "rfo = RandomForestClassifier().fit(x_meta, Y)\n",
    "imprf = rfo.feature_importances_\n",
    "#print(imprf)\n",
    "\n",
    "print(x_meta.columns[np.argsort(imprf)[-6:-1]])\n",
    "\n",
    "tree = DecisionTreeClassifier().fit(x_meta, Y)\n",
    "imptree = tree.feature_importances_\n",
    "#print(imptree)\n",
    "print(x_meta.columns[np.argsort(imptree)[-6:-1]])\n",
    "\n",
    "\n",
    "# v resitvah se izris stolpicnega diagrama"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.4: Preizkusimo še meta regresijo. Za vsako od naših treh metod strojnega učenja nauči meta model, ki napoveduje njegovo natančnost. Kolikšen je $R^2$ vsakega meta modela, izračunana s 5-kratnim prečnim preverjanjem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "metode = {\"knn\", \"tree\", \"bayes\"}\n",
    "for metoda in metode:\n",
    "    y_meta = y_meta_all[metoda]\n",
    "\n",
    "    meta_model = RandomForestRegressor(100)\n",
    "    res_meta = cross_validate(meta_model, x_meta, y_meta, scoring=\"neg_mean_squared_error\")\n",
    "    rmse_meta = np.sqrt(-res_meta['test_score'].mean())\n",
    "\n",
    "    dummy_model = DummyRegressor()\n",
    "    res_dummy = cross_validate(dummy_model, x_meta, y_meta, scoring=\"neg_mean_squared_error\")\n",
    "    rmse_dummy = np.sqrt(-res_dummy['test_score']).mean()\n",
    "\n",
    "    print(f\"RMSE meta modela za {metoda}: {rmse_meta}\")\n",
    "    print(f\"RMSE dummy modela za {metoda}: {rmse_dummy}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.DODATNO: S posamičnimi regresijskimi meta modeli za natančost iz A.3 lahko napovedujemo tudi najboljši model, tako da pogledamo, katerera od napovedanih natančnosti je najvišja. Primerjaj napovedi najboljšega modela z meta klasifikacijo in z meta regresijo. Katera se obnese bolje?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Optimizacija hiperparametrov\n",
    "Vse razen najpreprostejših metod strojnega učenja imajo eno ali več nastavitev, ki jim pravimo hiperparametri. Primerna nastavitev hiperparametrov za dane podatke je pogosto prav tako pomembna kot izbira primerne metode. V knjižnici scikit-learn lahko seznam hiperparametrov vsake metode najdemo s klicem **model.get_params()**, da jih zares razumemo, pa je treba pogledati v dokumentacijo ali pa celo prebrati članek o metodi. \n",
    "\n",
    "B.1 Naredi model odločitvenega drevesa ter se poigraj z njegovimi hiperparametri. Verjetno bosta najpomembnejša **max_depth** in **min_samples_split**. Za računje uspešnosti modela uporabi metriko $R^2$ in prečno preverjanje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.763052\n",
      "1      0.417707\n",
      "2      0.167011\n",
      "3      1.034676\n",
      "4      0.512737\n",
      "         ...   \n",
      "995    0.608756\n",
      "996    0.707602\n",
      "997    0.217132\n",
      "998    1.055196\n",
      "999    1.170648\n",
      "Name: y, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"drugi_del_podatki.csv\")\n",
    "x = data.drop(\"y\", axis=1)\n",
    "y = data[\"y\"]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20649708104983802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tre = DecisionTreeRegressor(max_depth=100, min_samples_split=5)\n",
    "cvtre = cross_validate(tre, X_train, y_train, cv=5,\n",
    "    scoring=(['r2']),\n",
    "    return_train_score=True)\n",
    "\n",
    "r2 = cvtre['test_r2'].mean()\n",
    "print(r2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.2 Iskanje najboljših hiperparametrov lahko razumemo kot optimizacijski problem. Sci-kit learn nam ponuja nekaj orodij za avtomatsko optimizacijo. Najpreprostejša je **sklearn.model_selection.GridSearchCV**, ki preišče celoten kartezični produkt vrednosti hiperparametrov, ki nas zanimajo.\n",
    "Uporabi grid search, da preiščeš kombinacije hiperparametrov **2 <= max_depth < 50** in **2 <= min_samples_split < 400**. \n",
    "Metodi grid search nastavi **cv=5**, da bo izvajala notranje prečno preverjanje. Koristna nastavitev je tudi **refit=True**.\n",
    "\n",
    "Pomembno se je zavedati, da pri resni optimizaciji hiperparametrov prilagajamo model na celotno množico podatkov. Zato je dobra praksa pred optimizacijo ločiti podatke na učno in testno množico ter izvesti optimizacijo na učni množici, končni model pa evaluirati na testni množici. \n",
    "(Obstaja celo možnost gnezdenega prečnega preverjanja, a to pustimo za drugič.)\n",
    "\n",
    "Po opravljeni optimizaciji hiperparametrov lahko dobimo najboljše vrednosti z **grid_search.best_params_**, natreniran najboljši model pa z **grid_search.best_estimator_** (če smo nastavili refit=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
      "             param_grid=[{'max_depth': range(2, 50, 3),\n",
      "                          'min_samples_split': range(2, 400, 7)}])\n",
      "{'max_depth': 8, 'min_samples_split': 51}\n",
      "DecisionTreeRegressor(max_depth=8, min_samples_split=51)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "tree_param = [{'max_depth': range(2,50,3), 'min_samples_split': range(2,400, 7)}]\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(), tree_param, cv=5, refit=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(grid_search)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "\n",
    "\n",
    "\n",
    "# DOPOLNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.36163014968385987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "bestTree = grid_search.best_estimator_\n",
    "\n",
    "pred = bestTree.predict(X_test)\n",
    "R2 = r2_score(y_test, pred)\n",
    "print('R2:',R2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.3 Nariši še 2D vizualizacijo metrike $R^2$ za vse preizkušene kombinacije hiperparametrov. Pomagaš si lahko z **grid_search.param_grid**, **np.reshape**, **plt.imshow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# glej resitve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.DODATNO: poglej si in preizkusi še **RandomizedSearchCV**, **HalvingGridSearchCV** ter **HalvingRandomSearchCV**. Opisani so tukaj: https://scikit-learn.org/stable/modules/grid_search.html."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV...nakljucno izbira parametre iz poradelitve moznih parametrov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80a873d8e01e9d73112e4934f14699f35ee658793aaf46cacab1aa294d9f135d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
