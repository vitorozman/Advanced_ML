{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta model\n",
    "\n",
    "Najprej sem uvozil podatkovja iz openml ki ustrezajo: \n",
    "- stevila stolpcev med 100-130 \n",
    "- stevilo vrtsiv med 1000-2000\n",
    "\n",
    "Potem sem precistil podatkovja in obdrzal tistak ki primerna za primerjavo nasim podatkov.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obdrzal sem 50 podatkovij (12.7%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "from openml.tasks import TaskType\n",
    "\n",
    "import warnings\n",
    "\n",
    "# ne izpisuje opozoril\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "\n",
    "\n",
    "#print(podatkovja_all)\n",
    "\n",
    "def get_id_with_taks():\n",
    "    d = openml.datasets.list_datasets(number_instances='500..3000', number_features='20..150', output_format=\"dataframe\")\n",
    "    did = list(d[\"did\"]) #id vseh podatkovij\n",
    "    tid_key = {} # kjuc s katerim bom dostopal do taksov \n",
    "    tasks = openml.tasks.list_tasks(task_type=TaskType.SUPERVISED_CLASSIFICATION, output_format=\"dataframe\")\n",
    "    tid = list(tasks['tid']) #id task\n",
    "    tdid = list(tasks['did']) # id podatkovij za pripadajoci task\n",
    "    ID = []\n",
    "    for n,i in enumerate(tdid):\n",
    "        if i in did:\n",
    "           tid_key[i] = tid[n]\n",
    "           ID.append(i)\n",
    "    return (ID, tid_key)\n",
    "\n",
    "\n",
    "def precisti_podatkovja(podatkovja, did):\n",
    "    podatkovja_ok = {}\n",
    "    name_key = {}\n",
    "    for n, podatkovje in enumerate(podatkovja):\n",
    "        name_podatkovja = podatkovje.name\n",
    "        target = podatkovje.default_target_attribute\n",
    "        X, _, nominal, names = podatkovje.get_data()\n",
    "        # Vec pogojev, da podatkovje obdrzimo:\n",
    "\n",
    "        # ce ga nismo ze prej (tj. neke druge verzije)\n",
    "        name_ok = name_podatkovja not in podatkovja_ok\n",
    "\n",
    "        # ce ima znan target in je target en sam (in ne npr. \"Spol,Starost\")\n",
    "        targ_ok = target is not None and \",\" not in target\n",
    "\n",
    "        # ce je target nominalen (klasifikacija) in podatki nimajo nominalnih atributov\n",
    "        i_target = names.index(target) if targ_ok else 0\n",
    "        nomi_ok = nominal[i_target] and sum(nominal) == 1  # natanko en nominalen in to je target\n",
    "        if name_ok and targ_ok and nomi_ok:\n",
    "            podatkovja_ok[name_podatkovja] = n\n",
    "            name_key[name_podatkovja] = did[n]\n",
    "\n",
    "    n_vsa = len(podatkovja)\n",
    "    n_ok = len(podatkovja_ok)\n",
    "    print(f\"Obdrzal sem {n_ok} podatkovij ({100 * n_ok / n_vsa:.1f}%)\")\n",
    "    return podatkovja_ok, name_key\n",
    "\n",
    "\n",
    "\n",
    "ID, tid_key = get_id_with_taks()\n",
    "podatkovja_all = openml.datasets.get_datasets(ID)\n",
    "podatkovja_ok, name_key = precisti_podatkovja(podatkovja_all, ID)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potem sem izbral primerne meta znacilke s pomocjo **pymfe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymfe.mfe import MFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=RuntimeError)\n",
    "\n",
    "\n",
    "def generate_meta_ds(data_all, data_ok):\n",
    "    meta_ds = {\"name\": []}\n",
    "    for  data_name, n in data_ok.items():\n",
    "        ds = data_all[n]\n",
    "        target = ds.default_target_attribute\n",
    "        X, y,_,_ = ds.get_data(target=target)\n",
    "        X = np.array(X)\n",
    "        y = np.array([str(t) for t in y])\n",
    "        print(y)\n",
    "        try:\n",
    "            typ = type(X[0,np.isnan(X).any(axis=0)])\n",
    "        except:\n",
    "            continue\n",
    "        if typ == str:\n",
    "            imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent').fit(X)\n",
    "        else:\n",
    "            imp = SimpleImputer(missing_values=np.nan, strategy='mean').fit(X)\n",
    "        X = imp.transform(X)\n",
    "        mfe = MFE(groups=[\"general\", \"statistical\", \"info-theory\"])\n",
    "        mfe.fit(X, y)\n",
    "        att_names, att_values = mfe.extract()\n",
    "\n",
    "        mfeM = MFE(groups=[\"model-based\"])\n",
    "        tree = DecisionTreeClassifier()\n",
    "        tree.fit(X, y)\n",
    "        att_namesM, att_valuesM = mfeM.extract_from_model(tree)\n",
    "\n",
    "        att_names += att_namesM\n",
    "        att_values += att_valuesM\n",
    "\n",
    "        is_first = len(meta_ds) == 1\n",
    "        meta_ds[\"name\"].append(data_name)\n",
    "        for a_name, a_value in zip(att_names, att_values):\n",
    "            if is_first:\n",
    "                meta_ds[a_name] = [a_value]\n",
    "            else:\n",
    "                meta_ds[a_name].append(a_value)\n",
    "    return pd.DataFrame(data=meta_ds, index=None)\n",
    "\n",
    "\n",
    "metaDS = generate_meta_ds(data_all=podatkovja_all, data_ok=podatkovja_ok)\n",
    "metaDS.to_csv(\"meta_learning/metaDS.csv\", index=False)\n",
    "print(metaDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nato sem se opisal podatke.csv z mfe. Potem sem izbral 3 podobna podatkovja s pomocjo k=3 najblizjih sosedov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PieChart2' 'cardiotocography' 'wdbc']\n"
     ]
    }
   ],
   "source": [
    "dt = pd.read_csv('podatki.csv')\n",
    "X = np.array(dt.drop('y', axis=1))\n",
    "Y = dt['y']\n",
    "clas = Y.unique()\n",
    "Y = Y.replace(clas[0], 0)\n",
    "Y = Y.replace(clas[1], 1)\n",
    "y = np.array(Y)\n",
    "\n",
    "#genereramo opis podatkov z statistikami ipd\n",
    "mfe = MFE(groups=[\"general\", \"statistical\", \"info-theory\"])\n",
    "mfe.fit(X, y)\n",
    "attributs_names, attributs_values = mfe.extract()\n",
    "mfeM = MFE(groups=[\"model-based\"])\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X, y)\n",
    "att_namesM, att_valuesM = mfeM.extract_from_model(tree)\n",
    "\n",
    "attributs_names += att_namesM\n",
    "attributs_values += att_valuesM\n",
    "\n",
    "dt_mfe = pd.DataFrame(data={attributs_names[i]:attributs_values[i] for i in range(len(attributs_names))}, index=[1])\n",
    "np_mfe = dt_mfe.to_numpy()\n",
    "\n",
    "\n",
    "dt_meta = pd.read_csv('meta_learning/metaDS.csv')\n",
    "df_names = dt_meta['name'] #imena podatkov\n",
    "np_meta = dt_meta.drop('name', axis=1).to_numpy()\n",
    "np_meta[np.isinf(np_meta)] = np.nan\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean').fit(np_meta)\n",
    "np_meta = imp_mean.transform(np_meta)\n",
    "np_mfe = imp_mean.transform(np_mfe)\n",
    "#print(np.argwhere(np.isnan(np_meta)), 'nan')\n",
    "\n",
    "#from sklearn.impute import KNNImputer\n",
    "#imputer_meta = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "#np_meta = imputer_meta.fit_transform(np_meta)\n",
    "#np_meta = np.nan_to_num(np_meta, nan=0)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=3)\n",
    "neigh.fit(np_meta)\n",
    "\n",
    "#print(np.argwhere(np.isnan(np_mfe)))\n",
    "sosedi = neigh.kneighbors(np_mfe, 3, return_distance=False)[0]\n",
    "sosedi = np.array(df_names[sosedi])\n",
    "#sosedi = df_names[sosedi]\n",
    "print(sosedi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nato sem preveril kateri model je bil najboljsi za posamezno podatkovje od izbtanih treh s pomocjo **openml**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na podatlkih PieChart2 so bili izvedeni taski:\n",
      "Best model: weka.kf.AttributeSelection-BestFirst-CfsSubsetEval-ReplaceMissingValues-NaiveBayes(1)\n",
      "Best AUC: 0.846022\n",
      "\n",
      "Na podatlkih cardiotocography so bili izvedeni taski:\n",
      "Best model: weka.kf.RandomForest(1)\n",
      "Best AUC: 0.99804\n",
      "\n",
      "Na podatlkih cardiotocography so bili izvedeni taski:\n",
      "Best model: weka.kf.RandomForest(1)\n",
      "Best AUC: 0.99804\n",
      "\n",
      "Na podatlkih wdbc so bili izvedeni taski:\n",
      "Best model: sklearn.pipeline.Pipeline(imputation=openmlstudy14.preprocessing.ConditionalImputer,hotencoding=sklearn.preprocessing.data.OneHotEncoder,variencethreshold=sklearn.feature_selection.variance_threshold.VarianceThreshold,classifier=sklearn.ensemble.weight_boosting.AdaBoostClassifier(base_estimator=sklearn.tree.tree.DecisionTreeClassifier))(1)\n",
      "Best AUC: 0.996049363141483\n",
      "\n",
      "Na podatlkih wdbc so bili izvedeni taski:\n",
      "Best model: mlr.classif.xgboost(6)\n",
      "Best AUC: 0.995851\n",
      "\n",
      "Na podatlkih wdbc so bili izvedeni taski:\n",
      "Best model: sklearn.pipeline.Pipeline(imputer=sklearn.impute._base.SimpleImputer,estimator=sklearn.tree._classes.DecisionTreeClassifier)(25)\n",
      "Best AUC: 0.917094762433275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data_id = name_key[sosedi[0]]\n",
    "#task_id = tid_key[data_id]\n",
    "#print(data_id, task_id)\n",
    "\n",
    "def get_best_model(sosedi, name_key, metric):\n",
    "    '''\n",
    "    Sprejme najblizje sosede, kljuc za pridobitev id podatkovij iz imen in metriko\n",
    "    vrne najbolsi model glede na metrico za dane sosede\n",
    "    '''\n",
    "    id_key = {v: k for k, v in name_key.items()}\n",
    "    tasks = openml.tasks.list_tasks(task_type=TaskType.SUPERVISED_CLASSIFICATION, output_format=\"dataframe\")\n",
    "    k_tid = {name_key[sosedi[0]]:[], name_key[sosedi[1]]:[], name_key[sosedi[2]]:[]}\n",
    "    for i, iD in enumerate(tasks['did']):\n",
    "        if iD in k_tid:\n",
    "            k_tid[iD].append(np.array(tasks['tid'])[i])\n",
    "\n",
    "    models = {}\n",
    "    for data_id, task_ids in k_tid.items():\n",
    "        for task_id in task_ids:\n",
    "            evals = openml.evaluations.list_evaluations(function=metric, \n",
    "                                                        tasks=[task_id], \n",
    "                                                        output_format=\"dataframe\")\n",
    "            if evals.empty:\n",
    "                continue\n",
    "            else:\n",
    "                ix = evals['value'].idxmax()\n",
    "                flow_name = evals['flow_name'].iloc[ix]\n",
    "                value = evals['value'].iloc[ix]\n",
    "                name_data = id_key[data_id]\n",
    "                models[name_data] = [flow_name]\n",
    "                print(f\"Na podatlkih {name_data} so bili izvedeni taski:\\nBest model: {flow_name}\\nBest AUC: {value}\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "metric = \"area_under_roc_curve\"\n",
    "models = get_best_model(sosedi, name_key, metric)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testeranje najboljsih modelov na podatki.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[231], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m AdaBoostClassifier\n\u001b[0;32m---> 23\u001b[0m adaBoost \u001b[39m=\u001b[39m AdaBoostClassifier(base_estimator\u001b[39m=\u001b[39;49mDecisionTreeClassifier)\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[1;32m     26\u001b[0m xgBoost \u001b[39m=\u001b[39mxgb\u001b[39m.\u001b[39mXGBClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Documents/School/Master/1.Letnik/ML/Advanced_ML/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:162\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    159\u001b[0m sample_weight[zero_weight_mask] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[39m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost(\n\u001b[1;32m    163\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[1;32m    164\u001b[0m )\n\u001b[1;32m    166\u001b[0m \u001b[39m# Early termination\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/School/Master/1.Letnik/ML/Advanced_ML/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:569\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[39mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 569\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[1;32m    571\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m~/Documents/School/Master/1.Letnik/ML/Advanced_ML/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:576\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_boost_real\u001b[39m(\u001b[39mself\u001b[39m, iboost, X, y, sample_weight, random_state):\n\u001b[1;32m    575\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_estimator(random_state\u001b[39m=\u001b[39;49mrandom_state)\n\u001b[1;32m    578\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight)\n\u001b[1;32m    580\u001b[0m     y_predict_proba \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict_proba(X)\n",
      "File \u001b[0;32m~/Documents/School/Master/1.Letnik/ML/Advanced_ML/venv/lib/python3.11/site-packages/sklearn/ensemble/_base.py:198\u001b[0m, in \u001b[0;36mBaseEnsemble._make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_estimator\u001b[39m(\u001b[39mself\u001b[39m, append\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    193\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Make and configure a copy of the `estimator_` attribute.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[39m    Warning: This method should be used to properly instantiate new\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m    sub-estimators.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     estimator \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator_)\n\u001b[1;32m    199\u001b[0m     estimator\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{p: \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator_params})\n\u001b[1;32m    201\u001b[0m     \u001b[39m# TODO(1.3): Remove\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39m# max_features = 'auto' would cause warnings in every call to\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m# Tree.fit(..)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/School/Master/1.Letnik/ML/Advanced_ML/venv/lib/python3.11/site-packages/sklearn/base.py:73\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n\u001b[0;32m---> 73\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     74\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m             \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m             \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     80\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[1;32m     84\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('podatki.csv')\n",
    "X = data.drop('y', axis=1)\n",
    "Y = data['y']\n",
    "clas = Y.unique()\n",
    "Y = Y.replace(clas[0], 0)\n",
    "Y = Y.replace(clas[1], 1)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gNB = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(1).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaBoost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier).fit(X_train, y_train)\n",
    "\n",
    "import xgboost as xgb\n",
    "xgBoost =xgb.XGBClassifier(random_state=1,learning_rate=0.01).fit(X_train, y_train)\n",
    "\n",
    "pred = gNB.predict(X_test)\n",
    "aucNB= roc_auc_score(pred, y_test)\n",
    "print(f'gNB auc:{aucNB}')\n",
    "\n",
    "\n",
    "pred = rf.predict(X_test)\n",
    "aucrf = roc_auc_score(pred, y_test)\n",
    "print(f'rf auc:{aucrf}')\n",
    "\n",
    "\n",
    "pred = adaBoost.predict(X_test)\n",
    "aucada = roc_auc_score(pred, y_test)\n",
    "print(f'adaBoost auc:{aucada}')\n",
    "\n",
    "\n",
    "pred = xgBoost.predict(X_test)\n",
    "aucxg = roc_auc_score(pred, y_test)\n",
    "print(f'xgBoost auc:{aucxg}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44565 philippine_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "43895 ibm-employee-performance\n",
      "44424 eye_movements_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "44680 sylvine_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "1466 cardiotocography\n",
      "44738 robert_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "44623 mfeat-factors_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "44686 christine_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "44701 Fashion-MNIST_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "44546 gina_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "22 mfeat-zernike\n",
      "44572 ada_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "44560 madeline_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True\n",
      "36 segment\n",
      "{'id_sosed': [44565, 44566, 44567, 44563, 44564, 43895, 43897, 43905, 44424, 44439, 44426, 44441, 44425, 44440, 44423, 44438, 44427, 44442, 44680, 44682, 44679, 44681, 44678, 1466, 1560, 44738, 44740, 44741, 44742, 44739, 44623, 44686, 44626, 44701, 44699, 44702, 44698, 44625, 44700, 44627, 44624, 44546, 44543, 44545, 44544, 44547, 22, 995, 44572, 44569, 44570, 44571, 44568, 44560, 44562, 36, 958, 40984, 42859, 42860, 44559, 44561, 44558], 'name_sosed': ['philippine_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'philippine_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'philippine_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'philippine_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'philippine_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'ibm-employee-performance', 'ibm-employee-performance', 'ibm-employee-performance', 'eye_movements_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'eye_movements_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'sylvine_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'sylvine_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'sylvine_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'sylvine_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'sylvine_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'cardiotocography', 'cardiotocography', 'robert_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'robert_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'robert_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'robert_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'robert_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'mfeat-factors_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'christine_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'mfeat-factors_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'Fashion-MNIST_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'Fashion-MNIST_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'Fashion-MNIST_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'Fashion-MNIST_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'mfeat-factors_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'Fashion-MNIST_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'mfeat-factors_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'mfeat-factors_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'gina_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'gina_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'gina_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'gina_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'gina_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'mfeat-zernike', 'mfeat-zernike', 'ada_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'ada_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'ada_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'ada_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'ada_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True', 'madeline_seed_2_nrows_2000_nclasses_10_ncols_100_stratify_True', 'madeline_seed_4_nrows_2000_nclasses_10_ncols_100_stratify_True', 'segment', 'segment', 'segment', 'segment', 'segment', 'madeline_seed_1_nrows_2000_nclasses_10_ncols_100_stratify_True', 'madeline_seed_3_nrows_2000_nclasses_10_ncols_100_stratify_True', 'madeline_seed_0_nrows_2000_nclasses_10_ncols_100_stratify_True']}\n"
     ]
    }
   ],
   "source": [
    "id_sosedi = {'id_sosed': [], 'name_sosed':[]}\n",
    "\n",
    "uniq_name = []\n",
    "df = d.reset_index()\n",
    "for s in sosedi:\n",
    "    for i in range(len(df)):\n",
    "        #print(df['name'].iloc[i])\n",
    "        if df['name'].iloc[i] == s:\n",
    "            if df['name'].iloc[i].split('_')[0] not in uniq_name:\n",
    "                print(ids[i], df['name'].iloc[i])\n",
    "                uniq_name.append(df['name'].iloc[i].split('_')[0])\n",
    "            id_sosedi['id_sosed'].append(df['did'].iloc[i])\n",
    "            id_sosedi['name_sosed'].append(df['name'].iloc[i])\n",
    "\n",
    "#print(pd.DataFrame(id_sosedi))\n",
    "print(id_sosedi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - weka.kf.RandomForest\n",
    "2 - https://www.openml.org/search?type=flow&sort=runs&id=65%2F\n",
    "https://www.openml.org/search?type=flow&sort=runs&id=1196%2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6, 11, 12, 14, 15, 16, 18, 22, 23, 28, 29, 31, 32, 37, 43, 45, 49, 53, 219, 2074, 2079, 3021, 3022, 3481, 3549, 3560, 3573, 3902, 3903, 3904, 3913, 3917, 3918, 7592, 9910, 9946, 9952, 9957, 9960, 9964, 9971, 9976, 9977, 9978, 9981, 9985, 10093, 10101, 14952, 14954, 14965, 14969, 14970, 125920, 125922, 146195, 146800, 146817, 146819, 146820, 146821, 146822, 146824, 146825, 167119, 167120, 167121, 167124, 167125, 167140, 167141]\n",
      "[3]\n",
      "[6]\n",
      "[11]\n",
      "[12]\n",
      "[14]\n",
      "[]\n",
      "[15]\n",
      "[16]\n",
      "[14]\n",
      "[18]\n",
      "[22]\n",
      "[14, 16]\n",
      "[23]\n",
      "[28]\n",
      "[29]\n",
      "[31]\n",
      "[14, 16, 22]\n",
      "[32]\n",
      "[37]\n",
      "[44]\n",
      "[46]\n",
      "[50]\n",
      "[54]\n",
      "[151]\n",
      "[182]\n",
      "[188]\n",
      "[38]\n",
      "[307]\n",
      "[300]\n",
      "[458]\n",
      "[469]\n",
      "[554]\n",
      "[1049]\n",
      "[14, 16, 22, 31]\n",
      "[1050]\n",
      "[14, 16, 22, 31, 3902]\n",
      "[1053]\n",
      "[1063]\n",
      "[1067]\n",
      "[14, 16, 22, 31, 3902, 3903]\n",
      "[1068]\n",
      "[14, 16, 22, 31, 3902, 3903, 3917]\n",
      "[1590]\n",
      "[4134]\n",
      "[1510]\n",
      "[1489]\n",
      "[1494]\n",
      "[14, 16, 22, 31, 3902, 3903, 3917, 3918]\n",
      "[1497]\n",
      "[1501]\n",
      "[1480]\n",
      "[1485]\n",
      "[1486]\n",
      "[1487]\n",
      "[14, 16, 22, 31, 3902, 3903, 3917, 3918, 9957]\n",
      "[1468]\n",
      "[1475]\n",
      "[1462]\n",
      "[1464]\n",
      "[4534]\n",
      "[6332]\n",
      "[1461]\n",
      "[4538]\n",
      "[1478]\n",
      "[23381]\n",
      "[40499]\n",
      "[40668]\n",
      "[40966]\n",
      "[14, 16, 22, 31, 3902, 3903, 3917, 3918, 9957, 9978]\n",
      "[40982]\n",
      "[14, 16, 22, 31, 3902, 3903, 3917, 3918, 9957, 9978, 146800]\n",
      "[40994]\n",
      "[40983]\n",
      "[40975]\n",
      "[40984]\n",
      "[14, 16, 22, 31, 3902, 3903, 3917, 3918, 9957, 9978, 146800, 146817]\n",
      "[40979]\n",
      "[40996]\n",
      "[41027]\n",
      "[23517]\n",
      "[40923]\n",
      "[40927]\n",
      "[40978]\n",
      "[40670]\n",
      "[40701]\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "from openml import tasks\n",
    "\n",
    "\n",
    "\n",
    "benchmark = openml.study.get_suite('OpenML-CC18')\n",
    "print(benchmark.tasks)\n",
    "cc_ids = []\n",
    "for tid in benchmark.tasks:\n",
    "    tsk = tasks.list_tasks(output_format=\"dataframe\", task_id=[tid])\n",
    "    tsk = np.array(tsk['did'])\n",
    "    #print(tsk)\n",
    "    if tsk[0] in ids:\n",
    "        print(cc_ids)\n",
    "        cc_ids.append(tid)\n",
    "#print(tasks.list_tasks(output_format=\"dataframe\", task_id=[315]))\n",
    "#ids_task = benchmark.tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "939\n",
      "sklearn.pipeline.Pipeline(imputation=openmlstudy14.preprocessing.ConditionalImputer,hotencoding=sklearn.preprocessing.data.OneHotEncoder,variencethreshold=sklearn.feature_selection.variance_threshold.VarianceThreshold,classifier=sklearn.svm.classes.SVC)(1)\n",
      "16\n",
      "945\n",
      "sklearn.pipeline.Pipeline(imputation=openmlstudy14.preprocessing.ConditionalImputer,hotencoding=sklearn.preprocessing.data.OneHotEncoder,variencethreshold=sklearn.feature_selection.variance_threshold.VarianceThreshold,classifier=sklearn.svm.classes.SVC)(1)\n",
      "22\n",
      "2583\n",
      "sklearn.pipeline.Pipeline(imputation=openmlstudy14.preprocessing.ConditionalImputer,hotencoding=sklearn.preprocessing.data.OneHotEncoder,variencethreshold=sklearn.feature_selection.variance_threshold.VarianceThreshold,classifier=sklearn.svm.classes.SVC)(1)\n",
      "31\n",
      "9766\n",
      "sklearn.pipeline.Pipeline(pca=sklearn.decomposition.pca.PCA,randomforestclassifier=sklearn.ensemble.forest.RandomForestClassifier)(1)\n",
      "3902\n",
      "7084\n",
      "weka.RotationForest_PrincipalComponents_J48(14)\n",
      "3903\n",
      "7837\n",
      "sklearn.pipeline.Pipeline(imputer=sklearn.preprocessing.imputation.Imputer,pca=sklearn.decomposition.pca.PCA,randomforestclassifier=sklearn.ensemble.forest.RandomForestClassifier)(1)\n",
      "3917\n",
      "8111\n",
      "sklearn.pipeline.Pipeline(imputer=sklearn.preprocessing.imputation.Imputer,pca=sklearn.decomposition.pca.PCA,randomforestclassifier=sklearn.ensemble.forest.RandomForestClassifier)(1)\n",
      "3918\n",
      "114\n",
      "weka.RandomForest(9)\n",
      "9957\n",
      "9491\n",
      "sklearn.pipeline.Pipeline(imputation=hyperimp.utils.preprocessing.ConditionalImputer,hotencoding=sklearn.preprocessing.data.OneHotEncoder,variencethreshold=sklearn.feature_selection.variance_threshold.VarianceThreshold,clf=sklearn.ensemble.forest.RandomForestClassifier)(1)\n",
      "9978\n",
      "717\n",
      "sklearn.pipeline.Pipeline(imputation=openmlstudy14.preprocessing.ConditionalImputer,hotencoding=sklearn.preprocessing.data.OneHotEncoder,variencethreshold=sklearn.feature_selection.variance_threshold.VarianceThreshold,classifier=sklearn.ensemble.weight_boosting.AdaBoostClassifier(base_estimator=sklearn.tree.tree.DecisionTreeClassifier))(1)\n",
      "146800\n",
      "27\n",
      "weka.classifiers.functions.SMO(weka.classifiers.functions.supportVector.RBFKernel,weka.classifiers.functions.Logistic)(1)\n",
      "146817\n",
      "4275\n",
      "sklearn.pipeline.Pipeline(simpleimputer=sklearn.impute._base.SimpleImputer,histgradientboostingclassifier=sklearn.ensemble._hist_gradient_boosting.gradient_boosting.HistGradientBoostingClassifier)(1)\n",
      "146822\n",
      "25\n",
      "weka.classifiers.trees.RandomForest(1)\n"
     ]
    }
   ],
   "source": [
    "for task_id in cc_ids:  # iterate over all tasks\n",
    "    #tasks.list_tasks(output_format=\"dataframe\", task_id=[task_id])\n",
    "    print(task_id)\n",
    "\n",
    "# Return benchmark results\n",
    "    evalv = openml.evaluations.list_evaluations(\n",
    "                function=\"area_under_roc_curve\", \n",
    "                tasks=[task_id], \n",
    "                output_format=\"dataframe\"\n",
    "            )\n",
    "    print(np.array(evalv['value']).argmax())\n",
    "    print(np.array(evalv['flow_name'])[np.array(evalv['value']).argmax()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939\n",
      "sklearn.pipeline.Pipeline(imputation=openmlstudy14.preprocessing.ConditionalImputer,hotencoding=sklearn.preprocessing.data.OneHotEncoder,variencethreshold=sklearn.feature_selection.variance_threshold.VarianceThreshold,classifier=sklearn.svm.classes.SVC)(1)\n"
     ]
    }
   ],
   "source": [
    "evalv = openml.evaluations.list_evaluations(\n",
    "                function=\"area_under_roc_curve\", \n",
    "                tasks=[14], \n",
    "                output_format=\"dataframe\"\n",
    "        )\n",
    "print(np.array(evalv['value']).argmax())\n",
    "print(np.array(evalv['flow_name'])[np.array(evalv['value']).argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         did                                               name  version  \\\n",
      "313      313                                       spectrometer        1   \n",
      "315      315                                           us_crime        1   \n",
      "316      316                                          yeast_ml8        1   \n",
      "588      588                                    fri_c4_1000_100        1   \n",
      "610      610                                     fri_c4_500_100        1   \n",
      "...      ...                                                ...      ...   \n",
      "44789  44789  KDDCup09-Upselling_seed_1_nrows_2000_nclasses_...        1   \n",
      "44790  44790  KDDCup09-Upselling_seed_2_nrows_2000_nclasses_...        1   \n",
      "44791  44791  KDDCup09-Upselling_seed_3_nrows_2000_nclasses_...        1   \n",
      "44792  44792  KDDCup09-Upselling_seed_4_nrows_2000_nclasses_...        1   \n",
      "44965  44965                       geographical_origin_of_music        7   \n",
      "\n",
      "      uploader  status format  MajorityClassSize  MaxNominalAttDistinctValues  \\\n",
      "313         94  active   ARFF               55.0                        531.0   \n",
      "315         94  active   ARFF                NaN                          NaN   \n",
      "316         94  active   ARFF             2383.0                          2.0   \n",
      "588          2  active   ARFF                NaN                          NaN   \n",
      "610          2  active   ARFF                NaN                          NaN   \n",
      "...        ...     ...    ...                ...                          ...   \n",
      "44789    32840  active   arff             1853.0                          NaN   \n",
      "44790    32840  active   arff             1853.0                          NaN   \n",
      "44791    32840  active   arff             1853.0                          NaN   \n",
      "44792    32840  active   arff             1853.0                          NaN   \n",
      "44965    30127  active   arff                NaN                          NaN   \n",
      "\n",
      "       MinorityClassSize  NumberOfClasses  NumberOfFeatures  \\\n",
      "313                  1.0             48.0             102.0   \n",
      "315                  NaN              0.0             128.0   \n",
      "316                 34.0              2.0             117.0   \n",
      "588                  NaN              0.0             101.0   \n",
      "610                  NaN              0.0             101.0   \n",
      "...                  ...              ...               ...   \n",
      "44789              147.0              2.0             101.0   \n",
      "44790              147.0              2.0             101.0   \n",
      "44791              147.0              2.0             101.0   \n",
      "44792              147.0              2.0             101.0   \n",
      "44965                NaN              0.0             117.0   \n",
      "\n",
      "       NumberOfInstances  NumberOfInstancesWithMissingValues  \\\n",
      "313                531.0                                 0.0   \n",
      "315               1994.0                              1871.0   \n",
      "316               2417.0                                 0.0   \n",
      "588               1000.0                                 0.0   \n",
      "610                500.0                                 0.0   \n",
      "...                  ...                                 ...   \n",
      "44789             2000.0                              2000.0   \n",
      "44790             2000.0                              2000.0   \n",
      "44791             2000.0                                 0.0   \n",
      "44792             2000.0                              2000.0   \n",
      "44965             1059.0                                 0.0   \n",
      "\n",
      "       NumberOfMissingValues  NumberOfNumericFeatures  \\\n",
      "313                      0.0                    100.0   \n",
      "315                  39202.0                    127.0   \n",
      "316                      0.0                    103.0   \n",
      "588                      0.0                    101.0   \n",
      "610                      0.0                    101.0   \n",
      "...                      ...                      ...   \n",
      "44789                 7121.0                     99.0   \n",
      "44790                 5914.0                    100.0   \n",
      "44791                    0.0                    100.0   \n",
      "44792                 9426.0                     98.0   \n",
      "44965                    0.0                    117.0   \n",
      "\n",
      "       NumberOfSymbolicFeatures  \n",
      "313                         2.0  \n",
      "315                         0.0  \n",
      "316                        14.0  \n",
      "588                         0.0  \n",
      "610                         0.0  \n",
      "...                         ...  \n",
      "44789                       2.0  \n",
      "44790                       1.0  \n",
      "44791                       1.0  \n",
      "44792                       3.0  \n",
      "44965                       0.0  \n",
      "\n",
      "[134 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
