{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta model\n",
    "\n",
    "Najprej sem uvozil podatkovja iz openml ki ustrezajo: \n",
    "- za podatkovje obstaja task z nadzarovano ucenje klasifikacije\n",
    "- stevila stolpcev med 20-150 \n",
    "- stevilo vrtsiv med 500-3000\n",
    "\n",
    "Potem sem precistil podatkovja in obdrzal tistak ki so primerna za primerjavo nasim podatkov.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obdrzal sem 50 podatkovij (12.7%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "from openml.tasks import TaskType\n",
    "\n",
    "import warnings\n",
    "\n",
    "# ne izpisuje opozoril\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "\n",
    "def get_id_with_taks():\n",
    "    \"\"\"\n",
    "    Iz openml pridobimo ID datasetov za katere so izvedeni taski nadzarovanega ucenja kasifikacije, ki vstrezajo poguju dimezij.\n",
    "    Vrne ID datatesot\n",
    "    \"\"\"\n",
    "    d = openml.datasets.list_datasets(number_instances='500..3000', number_features='20..150', output_format=\"dataframe\")\n",
    "    did = list(d[\"did\"]) #id vseh podatkovij\n",
    "    tasks = openml.tasks.list_tasks(task_type=TaskType.SUPERVISED_CLASSIFICATION, output_format=\"dataframe\")\n",
    "    tid = list(tasks['tid']) #id task\n",
    "    tdid = list(tasks['did']) # id podatkovij za pripadajoci task\n",
    "    ID = []\n",
    "    for i in tdid:\n",
    "        if i in did:\n",
    "           ID.append(i)\n",
    "    return ID\n",
    "\n",
    "\n",
    "def precisti_podatkovja(podatkovja, did):\n",
    "    \"\"\"Precisti podatkovja tako da izbere samo primerne za nas primer\n",
    "    Vrne primerna podatvoja in kljuc za pridobitev imen podatkovij {data_name : data_id}\"\"\"\n",
    "    \n",
    "    podatkovja_ok = {}\n",
    "    name_key = {}\n",
    "    for n, podatkovje in enumerate(podatkovja):\n",
    "        name_podatkovja = podatkovje.name\n",
    "        target = podatkovje.default_target_attribute\n",
    "        X, _, nominal, names = podatkovje.get_data()\n",
    "        # Vec pogojev, da podatkovje obdrzimo:\n",
    "\n",
    "        # ce ga nismo ze prej (tj. neke druge verzije)\n",
    "        name_ok = name_podatkovja not in podatkovja_ok\n",
    "\n",
    "        # ce ima znan target in je target en sam (in ne npr. \"Spol,Starost\")\n",
    "        targ_ok = target is not None and \",\" not in target\n",
    "\n",
    "        # ce je target nominalen (klasifikacija) in podatki nimajo nominalnih atributov\n",
    "        i_target = names.index(target) if targ_ok else 0\n",
    "        nomi_ok = nominal[i_target] and sum(nominal) == 1  # natanko en nominalen in to je target\n",
    "        if name_ok and targ_ok and nomi_ok:\n",
    "            podatkovja_ok[name_podatkovja] = n\n",
    "            name_key[name_podatkovja] = did[n]\n",
    "\n",
    "    n_vsa = len(podatkovja)\n",
    "    n_ok = len(podatkovja_ok)\n",
    "    print(f\"Obdrzal sem {n_ok} podatkovij ({100 * n_ok / n_vsa:.1f}%)\")\n",
    "    return podatkovja_ok, name_key\n",
    "\n",
    "\n",
    "ID = get_id_with_taks()\n",
    "podatkovja_all = openml.datasets.get_datasets(ID)\n",
    "podatkovja_ok, name_key = precisti_podatkovja(podatkovja_all, ID)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Izbira metaznacilk\n",
    "\n",
    "Izbral sem znacilke tipa \"general\", \"statistical\", \"info-theory\" in \"model-based\" (odlocitveno drevo) ter upirabil **pymfe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name  attr_conc.mean  attr_conc.sd  attr_ent.mean   attr_ent.sd  \\\n",
      "0   mfeat-fourier        0.013520      0.008569       3.584956  1.472658e-06   \n",
      "1  mfeat-karhunen        0.008939      0.002906       3.584957  1.083121e-06   \n",
      "2   mfeat-zernike        0.022655      0.064117       3.584957  1.795561e-15   \n",
      "3         segment        0.073432      0.090473       3.157775  1.288127e+00   \n",
      "4       oil_spill        0.062405      0.055971       2.848414  7.736935e-01   \n",
      "\n",
      "   attr_to_inst  can_cor.mean  can_cor.sd  cat_to_num  class_conc.mean  ...  \\\n",
      "0      0.038000      0.721437    0.230074         0.0         0.038622  ...   \n",
      "1      0.032000      0.809847    0.114468         0.0         0.036046  ...   \n",
      "2      0.023500      0.716099    0.255786         0.0         0.053979  ...   \n",
      "3      0.008225      0.746033    0.262599         0.0         0.145581  ...   \n",
      "4      0.052295      0.652479         NaN         0.0         0.013217  ...   \n",
      "\n",
      "   nodes_repeated.mean  nodes_repeated.sd  tree_depth.mean  tree_depth.sd  \\\n",
      "0             3.309859           2.252564        10.212314       3.650931   \n",
      "1             3.363636           2.280056         8.199461       2.573902   \n",
      "2             7.234043           2.943030        14.443465       9.135425   \n",
      "3             4.733333           3.011091         9.790210       3.577813   \n",
      "4             1.789474           1.031662         5.594203       2.675152   \n",
      "\n",
      "   tree_imbalance.mean  tree_imbalance.sd  tree_shape.mean  tree_shape.sd  \\\n",
      "0             0.051777           0.075185         0.023251       0.049506   \n",
      "1             0.078652           0.089569         0.033043       0.045687   \n",
      "2             0.020912           0.049068         0.016257       0.042493   \n",
      "3             0.053698           0.099012         0.034892       0.089367   \n",
      "4             0.112029           0.174346         0.125614       0.104012   \n",
      "\n",
      "   var_importance.mean  var_importance.sd  \n",
      "0             0.013158           0.027575  \n",
      "1             0.015625           0.029721  \n",
      "2             0.021277           0.026534  \n",
      "3             0.052632           0.097832  \n",
      "4             0.020408           0.051262  \n",
      "\n",
      "[5 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "from pymfe.mfe import MFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=RuntimeError)\n",
    "\n",
    "def generate_meta_ds(data_all, data_ok):\n",
    "    \"\"\" Sprejme vsa podatkovja in slovar primernih podatkovij.\n",
    "    Izvede generirane meta podatkovja za izbrane metaznacilke, za podatkoja ki vsebujejo nan izvede Imputacijo.\n",
    "    Vrne meta podatkovje.\"\"\"\n",
    "\n",
    "    meta_ds = {\"name\": []}\n",
    "    for  data_name, n in data_ok.items():\n",
    "        ds = data_all[n]\n",
    "        target = ds.default_target_attribute\n",
    "        X, y,_,_ = ds.get_data(target=target)\n",
    "        X = np.array(X)\n",
    "        y = np.array([str(t) for t in y])\n",
    "        try:\n",
    "            typ = type(X[0,np.isnan(X).any(axis=0)])\n",
    "        except:\n",
    "            continue\n",
    "        if typ == str:\n",
    "            imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent').fit(X)\n",
    "        else:\n",
    "            imp = SimpleImputer(missing_values=np.nan, strategy='mean').fit(X)\n",
    "        X = imp.transform(X)\n",
    "        mfe = MFE(groups=[\"general\", \"statistical\", \"info-theory\"])\n",
    "        mfe.fit(X, y)\n",
    "        att_names, att_values = mfe.extract()\n",
    "\n",
    "        mfeM = MFE(groups=[\"model-based\"])\n",
    "        tree = DecisionTreeClassifier()\n",
    "        tree.fit(X, y)\n",
    "        att_namesM, att_valuesM = mfeM.extract_from_model(tree)\n",
    "\n",
    "        att_names += att_namesM\n",
    "        att_values += att_valuesM\n",
    "\n",
    "        is_first = len(meta_ds) == 1\n",
    "        meta_ds[\"name\"].append(data_name)\n",
    "        for a_name, a_value in zip(att_names, att_values):\n",
    "            if is_first:\n",
    "                meta_ds[a_name] = [a_value]\n",
    "            else:\n",
    "                meta_ds[a_name].append(a_value)\n",
    "    return pd.DataFrame(data=meta_ds, index=None)\n",
    "\n",
    "metaDS = generate_meta_ds(data_all=podatkovja_all, data_ok=podatkovja_ok)\n",
    "metaDS.to_csv(\"meta_learning/metaDS.csv\", index=False)\n",
    "print(metaDS.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iskanej podobih datasetov\n",
    "\n",
    "Sledi transalcija mojih podatkov v prostor meta znacilk, za namen iskanja najblizjih sosedov. Izbral sem tri podatkovja iz openml ki se najblizja mojim \n",
    "podatkov s pomocjo **NearestNeighbors** za parameter k=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PieChart2' 'cardiotocography' 'wdbc']\n"
     ]
    }
   ],
   "source": [
    "dt = pd.read_csv('podatki.csv')\n",
    "X = np.array(dt.drop('y', axis=1))\n",
    "Y = dt['y']\n",
    "clas = Y.unique()\n",
    "Y = Y.replace(clas[0], 0)\n",
    "Y = Y.replace(clas[1], 1)\n",
    "y = np.array(Y)\n",
    "\n",
    "#genereramo opis podatkov z statistikami ipd\n",
    "mfe = MFE(groups=[\"general\", \"statistical\", \"info-theory\"])\n",
    "mfe.fit(X, y)\n",
    "attributs_names, attributs_values = mfe.extract()\n",
    "mfeM = MFE(groups=[\"model-based\"])\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X, y)\n",
    "att_namesM, att_valuesM = mfeM.extract_from_model(tree)\n",
    "\n",
    "attributs_names += att_namesM\n",
    "attributs_values += att_valuesM\n",
    "\n",
    "dt_mfe = pd.DataFrame(data={attributs_names[i]:attributs_values[i] for i in range(len(attributs_names))}, index=[1])\n",
    "np_mfe = dt_mfe.to_numpy()\n",
    "\n",
    "\n",
    "dt_meta = pd.read_csv('meta_learning/metaDS.csv')\n",
    "df_names = dt_meta['name'] #imena podatkov\n",
    "np_meta = dt_meta.drop('name', axis=1).to_numpy()\n",
    "np_meta[np.isinf(np_meta)] = np.nan\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean').fit(np_meta)\n",
    "np_meta = imp_mean.transform(np_meta)\n",
    "np_mfe = imp_mean.transform(np_mfe)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=3)\n",
    "neigh.fit(np_meta)\n",
    "\n",
    "sosedi = neigh.kneighbors(np_mfe, 3, return_distance=False)[0]\n",
    "sosedi = np.array(df_names[sosedi])\n",
    "print(sosedi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Izbira najboljsega modela\n",
    "\n",
    "Za izbrane najbljizje sosede sem preveril njihove rezultate na **OpenML**-ju. Ker za dano podatkoje obstaja vec moznih taksov sem preveril vsa ter izbral modele, ki so imela najboljsi \"area_under_roc_curve\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na podatlkih PieChart2 so bili izvedeni taski:\n",
      "Best model: weka.kf.AttributeSelection-BestFirst-CfsSubsetEval-ReplaceMissingValues-NaiveBayes(1)\n",
      "Best AUC: 0.846022\n",
      "\n",
      "Na podatlkih cardiotocography so bili izvedeni taski:\n",
      "Best model: weka.kf.RandomForest(1)\n",
      "Best AUC: 0.99804\n",
      "\n",
      "Na podatlkih cardiotocography so bili izvedeni taski:\n",
      "Best model: weka.kf.RandomForest(1)\n",
      "Best AUC: 0.99804\n",
      "\n",
      "Na podatlkih wdbc so bili izvedeni taski:\n",
      "Best model: sklearn.pipeline.Pipeline(imputation=openmlstudy14.preprocessing.ConditionalImputer,hotencoding=sklearn.preprocessing.data.OneHotEncoder,variencethreshold=sklearn.feature_selection.variance_threshold.VarianceThreshold,classifier=sklearn.ensemble.weight_boosting.AdaBoostClassifier(base_estimator=sklearn.tree.tree.DecisionTreeClassifier))(1)\n",
      "Best AUC: 0.996049363141483\n",
      "\n",
      "Na podatlkih wdbc so bili izvedeni taski:\n",
      "Best model: mlr.classif.xgboost(6)\n",
      "Best AUC: 0.995851\n",
      "\n",
      "Na podatlkih wdbc so bili izvedeni taski:\n",
      "Best model: sklearn.pipeline.Pipeline(imputer=sklearn.impute._base.SimpleImputer,estimator=sklearn.tree._classes.DecisionTreeClassifier)(25)\n",
      "Best AUC: 0.917094762433275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_best_model(sosedi, name_key, metric):\n",
    "    '''\n",
    "    Sprejme najblizje sosede, kljuc za pridobitev id podatkovij iz imen ter metriko\n",
    "    vrne najbolsi model glede na metrico za dane sosede\n",
    "    '''\n",
    "    id_key = {v: k for k, v in name_key.items()}\n",
    "    tasks = openml.tasks.list_tasks(task_type=TaskType.SUPERVISED_CLASSIFICATION, output_format=\"dataframe\")\n",
    "    k_tid = {name_key[sosedi[0]]:[], name_key[sosedi[1]]:[], name_key[sosedi[2]]:[]}\n",
    "    for i, iD in enumerate(tasks['did']):\n",
    "        if iD in k_tid:\n",
    "            k_tid[iD].append(np.array(tasks['tid'])[i])\n",
    "\n",
    "    models = {}\n",
    "    for data_id, task_ids in k_tid.items():\n",
    "        for task_id in task_ids:\n",
    "            evals = openml.evaluations.list_evaluations(function=metric, \n",
    "                                                        tasks=[task_id], \n",
    "                                                        output_format=\"dataframe\")\n",
    "            if evals.empty:\n",
    "                continue\n",
    "            else:\n",
    "                ix = evals['value'].idxmax()\n",
    "                flow_name = evals['flow_name'].iloc[ix]\n",
    "                value = evals['value'].iloc[ix]\n",
    "                name_data = id_key[data_id]\n",
    "                models[name_data] = [flow_name]\n",
    "                print(f\"Na podatlkih {name_data} so bili izvedeni taski:\\nBest model: {flow_name}\\nBest AUC: {value}\\n\")\n",
    "\n",
    "    return models\n",
    "\n",
    "metric = \"area_under_roc_curve\"\n",
    "models = get_best_model(sosedi, name_key, metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testiranje modelov\n",
    "\n",
    "Modele sem preizkusil na mojih podatkih, AUC sem izmeril na testnih podatkih. Potem sem prezkusil se skaliranje podatov in ponovno preveril AUC na testnih podatkih."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB with AUC: 0.6634495641344956\n",
      "RandomForestClassifier with AUC: 0.8066801619433198\n",
      "AdaBoostClassifier with AUC: 0.7159819347319347\n",
      "XGBClassifier with AUC: 0.8135118306351182\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('podatki.csv')\n",
    "X = data.drop('y', axis=1)\n",
    "Y = data['y']\n",
    "clas = Y.unique()\n",
    "Y = Y.replace(clas[0], 0)\n",
    "Y = Y.replace(clas[1], 1)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gNB = GaussianNB()\n",
    "gNB.fit(X_train, y_train)\n",
    "pred1 = gNB.predict(X_test)\n",
    "aucNB= roc_auc_score(pred1, y_test)\n",
    "print(f'GaussianNB with AUC: {aucNB}')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "pred2 = rf.predict(X_test)\n",
    "aucrf = roc_auc_score(pred2, y_test)\n",
    "print(f'RandomForestClassifier with AUC: {aucrf}')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaBoost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "adaBoost.fit(X_train, y_train)\n",
    "pred3 = adaBoost.predict(X_test)\n",
    "aucada = roc_auc_score(pred3, y_test)\n",
    "print(f'AdaBoostClassifier with AUC: {aucada}')\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "xgBoost =xgb.XGBClassifier()\n",
    "xgBoost.fit(X_train, y_train)\n",
    "pred4 = xgBoost.predict(X_test)\n",
    "aucxg = roc_auc_score(pred4, y_test)\n",
    "print(f'XGBClassifier with AUC: {aucxg}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skalirani!\n",
      "GaussianNB with AUC: 0.7406003159557661\n",
      "RandomForestClassifier with AUC: 0.8066801619433198\n",
      "AdaBoostClassifier with AUC: 0.7159819347319347\n",
      "XGBClassifier with AUC: 0.8135118306351182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"Skalirani!\")\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_train_sc = pd.DataFrame(X_train_sc,columns=X.columns)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "X_test_sc = pd.DataFrame(X_test_sc,columns=X.columns)\n",
    "\n",
    "gNBsc = GaussianNB()\n",
    "gNBsc.fit(X_train_sc, y_train)\n",
    "pred5 = gNBsc.predict(X_test_sc)\n",
    "aucNB= roc_auc_score(pred5, y_test)\n",
    "print(f'GaussianNB with AUC: {aucNB}')\n",
    "\n",
    "rfsc = RandomForestClassifier()\n",
    "rfsc.fit(X_train_sc, y_train)\n",
    "pred6 = rfsc.predict(X_test_sc)\n",
    "aucrf = roc_auc_score(pred6, y_test)\n",
    "print(f'RandomForestClassifier with AUC: {aucrf}')\n",
    "\n",
    "adaBoostsc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "adaBoostsc.fit(X_train_sc, y_train)\n",
    "pred7 = adaBoostsc.predict(X_test_sc)\n",
    "aucada = roc_auc_score(pred7, y_test)\n",
    "print(f'AdaBoostClassifier with AUC: {aucada}')\n",
    "\n",
    "xgBoostsc =xgb.XGBClassifier()\n",
    "xgBoostsc.fit(X_train_sc, y_train)\n",
    "pred8 = xgBoostsc.predict(X_test_sc)\n",
    "aucxg = roc_auc_score(pred8, y_test)\n",
    "print(f'XGBClassifier with AUC: {aucxg}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
